{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8438f662-1257-4a83-810f-56b830d75769",
   "metadata": {},
   "source": [
    "# Introduction to CUDA Programming\n",
    "\n",
    "<img src=\"./image1.svg\" width=\"1000\" height=\"800\">\n",
    "\n",
    "*Image credits: [Claude](claude.ai)*\n",
    "\n",
    "\n",
    "\n",
    "## What is CUDA?\n",
    "CUDA is NVIDIA's parallel computing platform that enables developers to use GPU acceleration for general-purpose computing. While GPUs were originally designed for graphics rendering, they've become powerful tools for:\n",
    "\n",
    "- Machine Learning\n",
    "- Scientific Computing\n",
    "- Data Analysis\n",
    "- Cryptography\n",
    "\n",
    "## Why Learn CUDA?\n",
    "### Consider this comparison:\n",
    "- CPU: Great at sequential tasks, like processing a single complex calculation\n",
    "- GPU: Excels at parallel tasks, like performing thousands of simple calculations simultaneously\n",
    "\n",
    "\n",
    "<img src=\"./cpugpug.svg\" width=\"500\" height=\"300\">\n",
    "\n",
    "### Example: Painting a House\n",
    "The painting house analogy illustrates the difference between CPU and GPU processing. A CPU is like a skilled artist creating a detailed mural, ideal for precise, intricate work. A GPU resembles a crew of painters quickly covering large areas with solid color, excelling at parallel, repetitive tasks.\n",
    "\n",
    "For a single detailed mural, the CPU takes 4 hours with high precision, while the GPU takes 6 hours but lacks finesse. This demonstrates the CPU's advantage in complex, single-threaded tasks.\n",
    "\n",
    "When painting 10 rooms solid white, the CPU takes 20 hours, but the GPU completes it in just 2 hours. This 10x speed increase showcases the GPU's strength in parallel processing and handling large-scale, repetitive tasks efficiently.\n",
    "\n",
    "This example highlights why GPUs excel at tasks like image processing, where many similar operations are performed simultaneously on different data points\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "We begin our exploration of CUDA programming with the essential fundamentals. You'll discover how code execution differs between CPU and GPU, building a strong foundation in:\n",
    "- Execution spaces and memory hierarchy\n",
    "- The shift from sequential to parallel thinking\n",
    "- Core parallel patterns that power GPU computing\n",
    "\n",
    "With these building blocks in place, we'll dive into CUDA's core concepts. Writing your first CUDA kernel is an exciting milestone - it's where theory transforms into practical GPU programming. You'll master thread organization and memory management, the key elements that make GPU computing powerful and efficient.\n",
    "\n",
    "The journey culminates in optimization techniques that unlock the GPU's full potential. Understanding advanced concepts like memory coalescing and bank conflicts might seem daunting now, but you'll soon discover how these skills can dramatically improve your code's performance.\n",
    "\n",
    "By the end of this course, you'll be able to:\n",
    "- Write efficient CUDA kernels from scratch\n",
    "- Understand when and how to leverage GPU acceleration\n",
    "- Optimize GPU code for maximum performance\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "- Basic C++ knowledge\n",
    "- Understanding of pointers and arrays\n",
    "- CUDA-capable NVIDIA GPU\n",
    "\n",
    "## Getting Started\n",
    "Let's verify your CUDA setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2f5129-b370-4955-ab03-2b021341062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  8 19:35:50 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:01:00.0 Off |                   On |\n",
      "| N/A   40C    P0            138W /  500W |    1312MiB /  81920MiB |     N/A      Default |\n",
      "|                                         |                        |              Enabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:41:00.0 Off |                   On |\n",
      "| N/A   32C    P0             64W /  500W |   10806MiB /  81920MiB |     N/A      Default |\n",
      "|                                         |                        |              Enabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:81:00.0 Off |                   On |\n",
      "| N/A   32C    P0             54W /  500W |      88MiB /  81920MiB |     N/A      Default |\n",
      "|                                         |                        |              Enabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:C1:00.0 Off |                   On |\n",
      "| N/A   28C    P0             52W /  500W |      88MiB /  81920MiB |     N/A      Default |\n",
      "|                                         |                        |              Enabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                            |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |                     Memory-Usage |        Vol|        Shared         |\n",
      "|      ID  ID  Dev |                       BAR1-Usage | SM     Unc| CE ENC  DEC  OFA  JPG |\n",
      "|                  |                                  |        ECC|                       |\n",
      "|==================+==================================+===========+=======================|\n",
      "|  1    5   0   0  |              25MiB / 19968MiB    | 28      0 |  2   0    1    0    0 |\n",
      "|                  |                 0MiB / 32767MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0    3    0     695684      C   gmx                                           190MiB |\n",
      "|    0    6    0     716380      C   python                                       1018MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA availability\n",
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9357be41-649e-4387-a642-43ba731d4372",
   "metadata": {},
   "source": [
    "To get started, please go through [Installation_instructions](Installation_instructions.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b908da9-15a7-4e00-9d7d-89c50b849150",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "In the following notebooks, we'll explore:\n",
    "1. Execution Spaces\n",
    "2. Memory Management\n",
    "3. Your First CUDA Kernel\n",
    "\n",
    "Ready to accelerate your ML code? Let's begin! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ff7b7-f3cd-4c8e-b0ca-e96d9e40a26d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
